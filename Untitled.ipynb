{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y = fetch_openml('mnist_784', version=1, data_home=\"./data/\", return_X_y=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X = X \n",
    "X = (X - np.average(X))/np.std(X) #標準化\n",
    "Y = Y.astype(\"int\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 10 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    plt.subplot(2, 5, i + 1)\n",
    "    plt.imshow(X[i * 6500].reshape(28, 28), cmap='gray_r')\n",
    "    plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x, test_x, train_y, test_y = train_test_split(X, Y, test_size=0.2, random_state=2)\n",
    "train_y = np.eye(10)[train_y].astype(np.int32)\n",
    "test_y = np.eye(10)[test_y].astype(np.int32)\n",
    "train_n = train_x.shape[0]\n",
    "test_n = test_x.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sigmoid:\n",
    "    def __init__(self):\n",
    "        self.y = None\n",
    "        \n",
    "    def __call__(self, x):\n",
    "        y = 1/(1+np.exp(-x))\n",
    "        self.y = y\n",
    "        return y\n",
    "    \n",
    "    def backward(self):\n",
    "        ry = self.y*(1 - self.y)\n",
    "        return ry "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReLU:\n",
    "    def __init__(self):\n",
    "        self.x = None\n",
    "        \n",
    "    def __call__(self, x):\n",
    "        self.x = x\n",
    "        return x * (x>0)\n",
    "    \n",
    "    def backward(self):\n",
    "        return 1 * (self.x>0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Softmax:\n",
    "    def __init__(self):\n",
    "        self.y = None\n",
    "        \n",
    "    def __call__(self, x):\n",
    "        exp_x = np.exp(x - x.max(axis=1, keepdims = True))\n",
    "        y = exp_x / np.sum(exp_x, axis=1, keepdims = True)\n",
    "        self.y = y\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class swish:\n",
    "    def __init__(self):\n",
    "        self.y = None\n",
    "        \n",
    "    def __call__(self, x, beta):\n",
    "        y = x*(1/(1+np.exp(-beta*x)))\n",
    "        return y\n",
    "    \n",
    "    def backward(self):\n",
    "        return y  #途中"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tanh(x):\n",
    "    return (np.exp(x) - np.exp(-x)) / (np.exp(x) + np.exp(-x))\n",
    "def softplus(x):\n",
    "    return np.log(1.0 + np.exp(x))\n",
    "def omega(x):\n",
    "    return 4*(x+1) + 4*np.exp(2*x) + np.exp(3*x) + np.exp(x)*(4*x+6)\n",
    "def delta(x):\n",
    "    return 2*np.exp(x) + np.exp(2*x) + 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class mish:\n",
    "    def __init__(self):\n",
    "        self.x = None\n",
    "      \n",
    "    def __call__(self, x):\n",
    "        self.x = x \n",
    "        y = x * tanh(softplus(x))\n",
    "        return y\n",
    "    \n",
    "    def backward(self):\n",
    "        y = np.exp(self.x) * omega(self.x) / delta(self.x)**2\n",
    "        return y  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Linear:\n",
    "    def __init__(self, in_dim, out_dim, activation):\n",
    "        self.W = np.random.uniform(low=-0.08, high=0.08, size=(in_dim, out_dim)) #ただの一様分布\n",
    "        #self.W = np.random.uniform() Xavierの一様分布\n",
    "        #\n",
    "        #self.W = np.random.normal(0, np.sqrt(2/in_dim), size=(in_dim, out_dim)) # Heの正規分布，　ReLU用\n",
    "        #self.W = np.random.uniform(low = -np.sqrt(in_dim), high = np.sqrt(in_dim), size=(in_dim, out_dim)) # Heの一様分布，　ReLU用\n",
    "        self.b = np.zeros(out_dim)\n",
    "        self.activation = activation()\n",
    "        self.delta = None\n",
    "        self.x = None\n",
    "        self.dW = None\n",
    "        self.db = None\n",
    "\n",
    "    def __call__(self, x):\n",
    "        # 順伝播計算\n",
    "        self.x = x\n",
    "        u = np.dot(x, self.W) + self.b  # self.W, self.b, x を用いて u を計算しよう\n",
    "        self.z = self.activation(u)\n",
    "        return self.z\n",
    "    \n",
    "    def backward(self, dout):\n",
    "        # 誤差計算\n",
    "        self.delta = dout*self.activation.backward() # dout と活性化関数の逆伝播 (self.activation.backward()) を用いて delta を計算しよう\n",
    "        dout = np.dot(self.delta, self.W.T) # self.delta, self.W を用いて 出力 o を計算しよう\n",
    "        \n",
    "        # 勾配計算\n",
    "        self.dW = np.dot(self.x.T,self.delta)  # dW を計算しよう\n",
    "        self.db = np.dot(np.ones(len(self.x)),self.delta)# db を計算しよう\n",
    "        \n",
    "        return dout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dropout:\n",
    "    def __init__(self, dropout_ratio):\n",
    "        self.dropout_ratio = dropout_ratio\n",
    "        self.mask = None\n",
    "\n",
    "    def forward(self, x, train_flg=True):\n",
    "        if train_flg:\n",
    "            self.mask = np.random.rand(*x.shape) > self.dropout_ratio\n",
    "            return x * self.mask\n",
    "        else:\n",
    "            return x * (1.0 - self.dropout_ratio)\n",
    "\n",
    "    def backward(self, dout):\n",
    "        return dout * self.mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP():\n",
    "    def __init__(self, layers):\n",
    "        self.layers = layers\n",
    "        \n",
    "    def train(self, x, t, lr):     \n",
    "        # 1. 順伝播\n",
    "        self.y = x\n",
    "        for layer in self.layers:\n",
    "            self.y = layer(self.y)  # 順伝播計算を順番に行い， 出力 y を計算しよう\n",
    "        \n",
    "        # 2. 損失関数の計算\n",
    "        self.loss = np.sum(-t*np.log(self.y + 1e-7)) / len(x)\n",
    "        \n",
    "        # 3. 誤差逆伝播\n",
    "        # 3.1. 最終層\n",
    "        # 3.1.1. 最終層の誤差・勾配計算\n",
    "        batchsize = len(self.layers[-1].x)\n",
    "        delta = (self.y - t) / batchsize\n",
    "        self.layers[-1].delta = delta\n",
    "        self.layers[-1].dW = np.dot(self.layers[-1].x.T, self.layers[-1].delta)\n",
    "        self.layers[-1].db = np.dot(np.ones(batchsize), self.layers[-1].delta)\n",
    "        dout = np.dot(self.layers[-1].delta, self.layers[-1].W.T)\n",
    "        \n",
    "        # 3.1.2. 最終層のパラメータ更新\n",
    "        self.layers[-1].W -= lr * self.layers[-1].dW # self.layers[-1].dW を用いて最終層の重みを更新しよう\n",
    "        self.layers[-1].b -= lr * self.layers[-1].db  # self.layers[-1].db を用いて最終層のバイアスを更新しよう\n",
    "        \n",
    "        # 3.2. 中間層\n",
    "        for layer in self.layers[-2::-1]:\n",
    "            # 3.2.1. 中間層の誤差・勾配計算\n",
    "            dout = layer.backward(dout)  # 逆伝播計算を順番に実行しよう\n",
    "            \n",
    "            # 3.2.2. パラメータの更新\n",
    "            layer.W -= lr * layer.dW  # 各層の重みを更新\n",
    "            layer.b -= lr *layer.db # 各層のバイアスを更新\n",
    "            \n",
    "        return self.loss\n",
    "\n",
    "    def test(self, x, t):\n",
    "        # 性能をテストデータで調べるために用いる\n",
    "        # よって，誤差逆伝播は不要\n",
    "        # 順伝播 (train関数と同様)\n",
    "        self.y = x\n",
    "        for layer in self.layers:\n",
    "            self.y = layer(self.y)\n",
    "        self.loss = np.sum(-t*np.log(self.y + 1e-7)) / len(x)\n",
    "        return self.loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_epoch=20, batchsize=100, lr=0.05\n",
      "epoch 0 | "
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'Dropout' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-33-31175f8c91c3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     17\u001b[0m             \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_x\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mperm\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mbatchsize\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m             \u001b[0mt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mperm\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mbatchsize\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m             \u001b[0msum_loss\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m             \u001b[0mpred_y\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m         \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msum_loss\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mtrain_n\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-13-04a4e578c550>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self, x, t, lr)\u001b[0m\n\u001b[0;32m      7\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# 順伝播計算を順番に行い， 出力 y を計算しよう\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m         \u001b[1;31m# 2. 損失関数の計算\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'Dropout' object is not callable"
     ]
    }
   ],
   "source": [
    "model = MLP([\n",
    "Linear(784, 1000, mish),\n",
    "Dropout(0.5),\n",
    "Linear(1000, 1000, mish),\n",
    "Linear(1000, 10, Softmax)])\n",
    "n_epoch = 20\n",
    "batchsize = 100\n",
    "for lr in [0.05, 0.02, 0.01, 0.005]:\n",
    "    print('n_epoch={}, batchsize={}, lr={}'.format(n_epoch,batchsize,lr))\n",
    "    for epoch in range(n_epoch):\n",
    "        print('epoch %d | ' % epoch, end=\"\")\n",
    "        sum_loss = 0\n",
    "        pred_y = []\n",
    "        perm = np.random.permutation(train_n)\n",
    "      \n",
    "        for i in range(0, train_n, batchsize):\n",
    "            x = train_x[perm[i: i+batchsize]]\n",
    "            t = train_y[perm[i: i+batchsize]]\n",
    "            sum_loss += model.train(x, t, lr) * len(x)\n",
    "            pred_y.extend(np.argmax(model.y, axis=1))\n",
    "        loss = sum_loss / train_n\n",
    "        accuracy = np.sum(np.eye(10)[pred_y] * train_y[perm]) / train_n\n",
    "        print('Train loss %.3f, accuracy %.4f | ' %(loss, accuracy), end=\"\")\n",
    "        sum_loss = 0\n",
    "        pred_y = []\n",
    "        for i in range(0, test_n, batchsize):\n",
    "            x = test_x[i: i+batchsize]\n",
    "            t = test_y[i: i+batchsize]\n",
    "            sum_loss += model.test(x, t) * len(x)\n",
    "            pred_y.extend(np.argmax(model.y, axis=1))\n",
    "        loss = sum_loss / test_n\n",
    "        accuracy = np.sum(np.eye(10)[pred_y] * test_y) / test_n\n",
    "        print('Test loss %.3f, accuracy %.4f' %(loss, accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "実行結果メモ\n",
    "\n",
    "(1)\n",
    "```\n",
    "model = MLP(\n",
    "[Linear(784, 1000, Sigmoid),\n",
    "Linear(1000, 1000, Sigmoid),\n",
    "Linear(1000, 10, Softmax)])\n",
    "n_epoch = 20*4\n",
    "batchsize = 100\n",
    "lr = 1,0.5,0.1,0.05,0.01\n",
    "```\n",
    "test accuracy: 0.9811\n",
    "\n",
    "(2)\n",
    "```\n",
    "model = MLP(\n",
    "[Linear(784, 1000, ReLU),\n",
    "Linear(1000, 1000, ReLU),\n",
    "Linear(1000, 10, Softmax)])\n",
    "n_epoch = 20\n",
    "batchsize = 100\n",
    "lr = 1,0.5,0.1,0.05,0.01\n",
    "```\n",
    "test accuracy: 0.9845\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
